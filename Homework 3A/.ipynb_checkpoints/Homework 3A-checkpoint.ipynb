{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_excel(\"HW3Avalidate.xlsx\") \n",
    "data_train = pd.read_excel(\"HW3Atrain.xlsx\")\n",
    "\n",
    "X_train = data_train.copy()\n",
    "X_train = X_train.drop('y', axis=1)\n",
    "Y_train = data_train.copy()\n",
    "Y_train = Y_train.drop('X_0', axis=1)\n",
    "Y_train = Y_train.drop('X_1', axis=1)\n",
    "\n",
    "X_test = data_test.copy()\n",
    "X_test = X_test.drop('y', axis=1)\n",
    "Y_test = data_test.copy()\n",
    "Y_test = Y_test.drop('X_0', axis=1)\n",
    "Y_test = Y_test.drop('X_1', axis=1)\n",
    "\n",
    "\n",
    "x_0_min = min(X_train['X_0'])\n",
    "x_0_max = max(X_train['X_0'])\n",
    "\n",
    "x_1_min = min(X_train['X_1'])\n",
    "x_1_max = max(X_train['X_1'])\n",
    "\n",
    "test_x_0_min = min(X_test['X_0'])\n",
    "test_x_0_max = max(X_test['X_0'])\n",
    "\n",
    "test_x_1_min = min(X_test['X_1'])\n",
    "test_x_1_max = max(X_test['X_1'])\n",
    "\n",
    "for i in range(len(X_train['X_0'])):\n",
    "    X_train['X_0'][i] = (X_train['X_0'][i]-x_0_min)/(x_0_max-x_0_min) #formula used for Min-Max\n",
    "    X_train['X_1'][i] = (X_train['X_1'][i]-x_1_min)/(x_1_max-x_1_min) #formula used for Min-Max\n",
    "    \n",
    "for i in range(len(X_test['X_0'])):\n",
    "    X_test['X_0'][i] = (X_test['X_0'][i]-x_0_min)/(x_0_max-x_0_min) #formula used for Min-Max\n",
    "    X_test['X_1'][i] = (X_test['X_1'][i]-x_1_min)/(x_1_max-x_1_min) #formula used for Min-Max\n",
    "'''\n",
    "training_data = []\n",
    "for i in range(len(X_train['X_0'])):\n",
    "    training_data.append([round(X_train['X_0'][i], 2),round(X_train['X_1'][i],2)])\n",
    "    \n",
    "testing_data = []\n",
    "for i in range(len(X_test['X_0'])):\n",
    "    testing_data.append([round(X_test['X_0'][i],2),round(X_test['X_1'][i],2)])\n",
    "\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(Y_train['y'])):\n",
    "    y_train.append([Y_train['y'][i]])\n",
    "    \n",
    "y_test = []\n",
    "\n",
    "for i in range(len(Y_test['y'])):\n",
    "    y_test.append([Y_test['y'][i]])\n",
    "'''\n",
    "\n",
    "training_data = np.empty((0,2), int)\n",
    "for i in range(len(X_train['X_0'])):\n",
    "    training_data = np.append(training_data, np.array([[X_train['X_0'][i],X_train['X_1'][i]]]), axis=0)\n",
    "    \n",
    "testing_data = np.empty((0,2), int)\n",
    "for i in range(len(X_test['X_0'])):\n",
    "    testing_data = np.append(testing_data, np.array([[X_test['X_0'][i],X_test['X_1'][i]]]), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "y_train = np.empty((0,1), int)\n",
    "for i in range(len(Y_train['y'])):\n",
    "    y_train = np.append(y_train, np.array([[Y_train['y'][i]]]), axis=0)\n",
    "\n",
    "y_test = np.empty((0,1), int)\n",
    "for i in range(len(Y_test['y'])):\n",
    "    y_test = np.append(y_test, np.array([[Y_test['y'][i]]]), axis=0)\n",
    "\n",
    "np_testing_y = np.array(y_test)\n",
    "np_testing_x = np.array(testing_data)\n",
    "np_training_x = np.array(training_data)\n",
    "np_training_y = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy-iteration: 53.41%\n",
      "Testing accuracy-iteration: 82.93% Learning rate --> 0.01\n",
      "Confusion matrix ---> TrueTrue: 32 TrueFalse: 36 FalseTrue: 5 FalseFalse 9\n",
      "Recall= 0.78\n",
      "Precision= 0.86\n",
      "Training accuracy-iteration: 50.00%\n",
      "Testing accuracy-iteration: 81.71% Learning rate --> 0.0099\n",
      "Confusion matrix ---> TrueTrue: 29 TrueFalse: 38 FalseTrue: 3 FalseFalse 12\n",
      "Recall= 0.71\n",
      "Precision= 0.91\n",
      "Training accuracy-iteration: 50.24%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.009801\n",
      "Confusion matrix ---> TrueTrue: 27 TrueFalse: 37 FalseTrue: 4 FalseFalse 14\n",
      "Recall= 0.66\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 51.22%\n",
      "Testing accuracy-iteration: 75.61% Learning rate --> 0.00970299\n",
      "Confusion matrix ---> TrueTrue: 26 TrueFalse: 36 FalseTrue: 5 FalseFalse 15\n",
      "Recall= 0.63\n",
      "Precision= 0.84\n",
      "Training accuracy-iteration: 52.44%\n",
      "Testing accuracy-iteration: 75.61% Learning rate --> 0.0096059601\n",
      "Confusion matrix ---> TrueTrue: 26 TrueFalse: 36 FalseTrue: 5 FalseFalse 15\n",
      "Recall= 0.63\n",
      "Precision= 0.84\n",
      "Training accuracy-iteration: 52.44%\n",
      "Testing accuracy-iteration: 76.83% Learning rate --> 0.009509900499\n",
      "Confusion matrix ---> TrueTrue: 26 TrueFalse: 37 FalseTrue: 4 FalseFalse 15\n",
      "Recall= 0.63\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 52.44%\n",
      "Testing accuracy-iteration: 76.83% Learning rate --> 0.00941480149401\n",
      "Confusion matrix ---> TrueTrue: 26 TrueFalse: 37 FalseTrue: 4 FalseFalse 15\n",
      "Recall= 0.63\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 52.44%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.0093206534790699\n",
      "Confusion matrix ---> TrueTrue: 27 TrueFalse: 37 FalseTrue: 4 FalseFalse 14\n",
      "Recall= 0.66\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 52.44%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.0092274469442792\n",
      "Confusion matrix ---> TrueTrue: 27 TrueFalse: 37 FalseTrue: 4 FalseFalse 14\n",
      "Recall= 0.66\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 51.95%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.009135172474836408\n",
      "Confusion matrix ---> TrueTrue: 27 TrueFalse: 37 FalseTrue: 4 FalseFalse 14\n",
      "Recall= 0.66\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 51.71%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.009043820750088045\n",
      "Confusion matrix ---> TrueTrue: 27 TrueFalse: 37 FalseTrue: 4 FalseFalse 14\n",
      "Recall= 0.66\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 51.46%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.008953382542587164\n",
      "Confusion matrix ---> TrueTrue: 27 TrueFalse: 37 FalseTrue: 4 FalseFalse 14\n",
      "Recall= 0.66\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 51.46%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.008863848717161293\n",
      "Confusion matrix ---> TrueTrue: 27 TrueFalse: 37 FalseTrue: 4 FalseFalse 14\n",
      "Recall= 0.66\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 51.46%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.00877521022998968\n",
      "Confusion matrix ---> TrueTrue: 27 TrueFalse: 37 FalseTrue: 4 FalseFalse 14\n",
      "Recall= 0.66\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 51.46%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.008687458127689783\n",
      "Confusion matrix ---> TrueTrue: 27 TrueFalse: 37 FalseTrue: 4 FalseFalse 14\n",
      "Recall= 0.66\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 51.46%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.008600583546412886\n",
      "Confusion matrix ---> TrueTrue: 27 TrueFalse: 37 FalseTrue: 4 FalseFalse 14\n",
      "Recall= 0.66\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 51.46%\n",
      "Testing accuracy-iteration: 76.83% Learning rate --> 0.008514577710948757\n",
      "Confusion matrix ---> TrueTrue: 26 TrueFalse: 37 FalseTrue: 4 FalseFalse 15\n",
      "Recall= 0.63\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 51.46%\n",
      "Testing accuracy-iteration: 76.83% Learning rate --> 0.00842943193383927\n",
      "Confusion matrix ---> TrueTrue: 26 TrueFalse: 37 FalseTrue: 4 FalseFalse 15\n",
      "Recall= 0.63\n",
      "Precision= 0.87\n",
      "Training accuracy-iteration: 51.46%\n",
      "Testing accuracy-iteration: 75.61% Learning rate --> 0.008345137614500876\n",
      "Confusion matrix ---> TrueTrue: 26 TrueFalse: 36 FalseTrue: 5 FalseFalse 15\n",
      "Recall= 0.63\n",
      "Precision= 0.84\n",
      "Training accuracy-iteration: 52.20%\n",
      "Testing accuracy-iteration: 75.61% Learning rate --> 0.008261686238355867\n",
      "Confusion matrix ---> TrueTrue: 26 TrueFalse: 36 FalseTrue: 5 FalseFalse 15\n",
      "Recall= 0.63\n",
      "Precision= 0.84\n",
      "Training accuracy-iteration: 52.93%\n",
      "Testing accuracy-iteration: 75.61% Learning rate --> 0.008179069375972308\n",
      "Confusion matrix ---> TrueTrue: 26 TrueFalse: 36 FalseTrue: 5 FalseFalse 15\n",
      "Recall= 0.63\n",
      "Precision= 0.84\n",
      "Training accuracy-iteration: 53.41%\n",
      "Testing accuracy-iteration: 75.61% Learning rate --> 0.008097278682212584\n",
      "Confusion matrix ---> TrueTrue: 26 TrueFalse: 36 FalseTrue: 5 FalseFalse 15\n",
      "Recall= 0.63\n",
      "Precision= 0.84\n",
      "Training accuracy-iteration: 53.66%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.00801630589539046\n",
      "Confusion matrix ---> TrueTrue: 28 TrueFalse: 36 FalseTrue: 5 FalseFalse 13\n",
      "Recall= 0.68\n",
      "Precision= 0.85\n",
      "Training accuracy-iteration: 55.12%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.007936142836436554\n",
      "Confusion matrix ---> TrueTrue: 28 TrueFalse: 36 FalseTrue: 5 FalseFalse 13\n",
      "Recall= 0.68\n",
      "Precision= 0.85\n",
      "Training accuracy-iteration: 55.85%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.007856781408072189\n",
      "Confusion matrix ---> TrueTrue: 28 TrueFalse: 36 FalseTrue: 5 FalseFalse 13\n",
      "Recall= 0.68\n",
      "Precision= 0.85\n",
      "Average training time for network running 40 iterations with batch size 5 --->1.1684125900268554s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Accuracy-best: 82.93% Learning rate --> 0.01\n",
      "TrueOne: 32 TrueZero: 36 FalseOne: 5 FalseZero 9\n"
     ]
    }
   ],
   "source": [
    "class Network_layer:\n",
    "    \n",
    "    def __init__(self, number_input, number_neurons, use_standard_activation):\n",
    "        #self.size = size\n",
    "        self.weights = (np.random.rand(number_input,number_neurons)*2) - 1\n",
    "        #self.weights = np.random.rand(number_input,number_neurons)\n",
    "        self.bias = np.zeros(number_neurons)\n",
    "        self.last_activation = None\n",
    "        self.use_standard_activation = use_standard_activation\n",
    "        self.error = None\n",
    "        self.delta = None\n",
    "        \n",
    "    def activate(self, x):\n",
    "        r = np.dot(x, self.weights) + self.bias\n",
    "        if self.use_standard_activation:\n",
    "            self.last_activation = self.activation(r)\n",
    "        else: \n",
    "            self.last_activation = self.tanh(r)\n",
    "            \n",
    "        return self.last_activation\n",
    "\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def activation(self, x):\n",
    "        #relu\n",
    "        if self.use_standard_activation:\n",
    "            x[x<0] = 0\n",
    "            return x\n",
    "        #tanh\n",
    "        return self.tanh(x)\n",
    "    \n",
    "    def activation_derivative(self, x):\n",
    "        #relu derivative\n",
    "        if self.use_standard_activation:\n",
    "            x[x>0] = 1\n",
    "            x[x<0] = 0\n",
    "            return x\n",
    "        #tanh derivative\n",
    "        return 1.0 - np.tanh(x)**2\n",
    "    \n",
    "\n",
    "class Neaural_net:\n",
    "    layers = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "    \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.activate(X)\n",
    "        return X\n",
    "\n",
    "    def softmax(self,X):\n",
    "        exps = np.exp(X)\n",
    "        return exps / np.sum(exps)\n",
    "    \n",
    "    def cross_entropy(self, X,y):\n",
    "        m = y.shape[0]\n",
    "        p = self.softmax(X)\n",
    "        \n",
    "        likelihood = -np.log(p[range(m), y.argmax(axis=1)])\n",
    "        loss = np.sum(likelihood) / m\n",
    "        return loss\n",
    "        \n",
    "    def logloss(self, true_label, predicted, eps=1e-15):\n",
    "        p = np.clip(predicted, eps, 1 - eps)\n",
    "        if true_label == 1:\n",
    "            return -math.log(p)\n",
    "        else:\n",
    "            return -math.log(1 - p) \n",
    "        \n",
    "    def mae(self, targets, predictions):\n",
    "        differences = predictions - targets\n",
    "        absolute_differences = np.absolute(differences)\n",
    "        mean_absolute_differences = absolute_differences.mean()\n",
    "        return mean_absolute_differences\n",
    "        \n",
    "    def mean_squared_error(self, actual, predicted):\n",
    "        sum_square_error = 0.0\n",
    "        for i in range(len(actual)):\n",
    "            sum_square_error += (actual[i] - predicted[i])**2.0\n",
    "        mean_square_error = sum_square_error / len(actual)\n",
    "\n",
    "        return mean_square_error\n",
    "        \n",
    "    def checkPrediction(self, y, pred):\n",
    "        pred = np.around(pred)\n",
    "        if pred == y:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "               \n",
    "        \n",
    "    def backpropagation(self, X, y, learning_rate):\n",
    "        output = self.feed_forward(X)\n",
    "        average_activation = None\n",
    "        correct_predictions = 0\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            layer = self.layers[i]\n",
    "            all_deltas = []\n",
    "            last_activations = []\n",
    "            for j in range(len(output)):\n",
    "                if layer == self.layers[-1]:\n",
    "                    layer.error =  y[j] - output[j]\n",
    "                    all_deltas.append(layer.error * layer.activation_derivative(output[j]))\n",
    "                    last_activations.append(layer.activation_derivative(output[j]))\n",
    "                    correct_predictions = correct_predictions + self.checkPrediction(y[j], output[j])\n",
    "                else:\n",
    "                    next_layer = self.layers[i + 1]\n",
    "                    layer.error = np.dot(next_layer.weights, next_layer.delta)\n",
    "                    all_deltas.append(layer.error * layer.activation_derivative(layer.last_activation[j]))\n",
    "                    last_activations.append(layer.activation_derivative(layer.last_activation[j]))\n",
    "                    \n",
    "            average_delta = sum(all_deltas)/float(len(output))\n",
    "            average_activation = sum(last_activations)/float(len(output))\n",
    "            layer.delta = average_delta\n",
    "    \n",
    "        # Update the weights\n",
    "        for j in range(len(output)):\n",
    "            for i in range(len(self.layers)):\n",
    "                layer = self.layers[i]\n",
    "                input_to_use = np.atleast_2d(X[j] if i == 0 else self.layers[i - 1].last_activation[j])\n",
    "                layer.weights += layer.delta * input_to_use.T * learning_rate\n",
    "        return correct_predictions\n",
    "            \n",
    "    \n",
    "    \n",
    "    def get_batch(self, inputs, targets, batchsize, shuffle=False):\n",
    "        assert len(inputs) == len(targets)\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(len(inputs))\n",
    "        for start in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "            if shuffle:\n",
    "                excerpt = indices[start:start + batchsize]\n",
    "            else:\n",
    "                excerpt = slice(start, start + batchsize)\n",
    "            yield inputs[excerpt], targets[excerpt] \n",
    "\n",
    "            \n",
    "    def train(self, X, y, learning_rate, max_epochs, batchsize):\n",
    "        mses = []\n",
    "        training_accuracy = []\n",
    "        for i in range(max_epochs):\n",
    "            correct_per_epoch = 0\n",
    "            for x_batch,y_batch in self.get_batch(X,y,batchsize=batchsize,shuffle=False):\n",
    "                correct_predictions_batch = self.backpropagation(x_batch,y_batch, learning_rate)\n",
    "                correct_per_epoch = correct_per_epoch + correct_predictions_batch\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                mse = np.mean(np.square(y - NN.feed_forward(X)))\n",
    "                mses.append(mse*100)\n",
    "                training_accuracy.append((correct_per_epoch/len(X))*100)\n",
    "        return mses, training_accuracy \n",
    "    \n",
    "    \n",
    "    \n",
    "    def test(self, X, y_true):\n",
    "        correct = 0\n",
    "        TT = 0 \n",
    "        TF = 0\n",
    "        FT = 0\n",
    "        FF = 0\n",
    "        for i in range(len(X)):\n",
    "            forward_pass = self.feed_forward(X[i])\n",
    "            pred = np.around(forward_pass)\n",
    "            y = y_true[i]\n",
    "            if pred == y:\n",
    "                correct = correct + 1\n",
    "            if pred == 1 and y == 1:\n",
    "                TT = TT + 1\n",
    "            if pred == 1 and y == 0:\n",
    "                FT = FT + 1\n",
    "            if pred == 0 and y == 1:\n",
    "                FF = FF + 1\n",
    "            if pred == 0 and y == 0:\n",
    "                TF = TF + 1\n",
    "            confusion = [TT, TF, FT, FF]\n",
    "        return correct/len(X), confusion\n",
    "\n",
    "\n",
    "\n",
    "NN = Neaural_net()\n",
    "NN.add_layer(Network_layer(2, 10, False))\n",
    "NN.add_layer(Network_layer(10, 10, False))\n",
    "NN.add_layer(Network_layer(10, 10, False))\n",
    "NN.add_layer(Network_layer(10,1, False))\n",
    "\n",
    "\n",
    "# Train the neural networks\n",
    "accuracy = []\n",
    "iteration = []\n",
    "learning_rate = 0.01\n",
    "total_error = []\n",
    "total_training_accuracy = []\n",
    "number_test = 25\n",
    "number_epoc = 40\n",
    "batchsize = 5\n",
    "last_mse = [0,0,0,0,0]\n",
    "a = 0\n",
    "total_time = 0\n",
    "max_accuracy = 0\n",
    "best_NN = copy.copy(NN)\n",
    "best_confusion = [0,0,0,0]\n",
    "best_learning_rate = learning_rate\n",
    "recall = []\n",
    "precision = []\n",
    "\n",
    "for i in range(1,number_test+1):\n",
    "    start = time.time()\n",
    "    errors, training_accuracy = NN.train(np_training_x, np_training_y, learning_rate, number_epoc, batchsize)\n",
    "    #print(\"first\", training_accuracy)\n",
    "    end = time.time()\n",
    "    total_time = total_time + (end-start)\n",
    "    total_error.append(errors)\n",
    "    total_training_accuracy.append(training_accuracy)\n",
    "    last_mse[a] = round(errors[0],2)\n",
    "    #print(last_mse[a])\n",
    "    a = a + 1\n",
    "    if a > 4:\n",
    "        a = 0\n",
    "    iteration.append(i*number_epoc)\n",
    "    accuracy_one, confusion = NN.test(np_testing_x, np_testing_y.flatten())\n",
    "    if(accuracy_one > max_accuracy):\n",
    "        max_accuracy = accuracy_one\n",
    "        best_NN = copy.deepcopy(NN)\n",
    "        best_confusion = confusion\n",
    "        best_learning_rate = learning_rate\n",
    "    print('Training accuracy-iteration: %.2f%%' % (training_accuracy[-1]))\n",
    "    print('Testing accuracy-iteration: %.2f%%' % (accuracy_one*100), \"Learning rate --> \"+ str(learning_rate))\n",
    "    print('Confusion matrix ---> TrueTrue:',confusion[0] ,'TrueFalse:',confusion[1], 'FalseTrue:',confusion[2] , 'FalseFalse',confusion[3] )\n",
    "    recall_tmp = round(confusion[0]/(confusion[0]+confusion[3]), 2)\n",
    "    precision_tmp = round(confusion[0]/(confusion[0]+confusion[2]), 2)\n",
    "    recall.append(recall_tmp)\n",
    "    print('Recall=', recall_tmp)\n",
    "    precision.append(precision_tmp)\n",
    "    print('Precision=', precision_tmp)\n",
    "    accuracy.append(accuracy_one*100)\n",
    "    mse_same = True\n",
    "    for i in range(len(last_mse)):\n",
    "        if round(last_mse[i],2) != round(errors[0],2):\n",
    "            mse_same = False\n",
    "    if mse_same:\n",
    "        print(\"MSE has converged!\")\n",
    "        break;\n",
    "    learning_rate = learning_rate*0.99\n",
    "\n",
    "\n",
    "\n",
    "print(\"Average training time for network running \" + str(number_epoc) + \" iterations with batch size \" + str(batchsize) + \" --->\" + str(total_time/number_test)+ \"s\")\n",
    "\n",
    "plt.plot(iteration,accuracy, label='Validation accuracy')\n",
    "plt.plot(iteration, total_error, label='Mean squared error')\n",
    "plt.plot(iteration, total_training_accuracy, label='Training accuracy')\n",
    "#plt.plot(iteration, recall, label='Recall')\n",
    "#plt.plot(iteration, precision, label='Precision')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('Accuracy & MSE(*100)')\n",
    "plt.axis((number_epoc,number_epoc*number_test,0,100))\n",
    "plt.title('Changes in Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "accuracy_one, confusion = best_NN.test(np_testing_x, np_testing_y.flatten())\n",
    "print(\"------------------------\")\n",
    "print('Accuracy-best: %.2f%%' % (accuracy_one*100), \"Learning rate --> \"+ str(best_learning_rate))\n",
    "print('TrueOne:',confusion[0] ,'TrueZero:',confusion[1], 'FalseOne:',confusion[2] , 'FalseZero',confusion[3] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (10 points) Activation and Loss functions. \n",
    "Please choose suitable activation functions φ(0), φ(1), φ(2) and a suitable Loss function to perform the task. Report and justify your choices in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (10 points) Learning rate, batch size, initialization. \n",
    "Please choose a suitable learning rate, batch size, initialization of the parameter values, and any other setting you may need. Discuss and justify your choices in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (10 points) Training. \n",
    "Make plots with the loss function computed over the training set and over the validation set. Stop the training when the error is small enough. Justify your stopping criterium. Report the final accuracy obtained and the confusion matrix on the validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (20 points) Implementation. \n",
    "We will run and check the uploaded Python file. To obtain the points for this subproblem, the Python file has to run (no errors) and the MLP model and the Backpropagation algorithm have to be implemented completely from scratch by you. You are not allowed to use any library which implements MLP models, but you are allowed to use auxiliary libraries, e.g. Numpy, Matplotlib, Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Peer Review paragraph (0 points)\n",
    "Finally, each group member must write a single paragraph outlining their opinion on the work distri- bution within the group. Did every group member contribute equally? Did you split up tasks in a fair manner, or jointly worked through the exercises. Do you think that some members of your group deserve a different grade from others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
