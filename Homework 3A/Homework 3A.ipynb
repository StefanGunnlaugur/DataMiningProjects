{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 4\n",
    "\n",
    "#### Team members:\n",
    "\n",
    "Arngrímur Einarsson  \n",
    "Guðmundur Orri Pálsson  \n",
    "Nick Geerjens  \n",
    "Stefán Gunnlaugur Jónsson  \n",
    "Troy The Legend  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_excel(\"HW3Avalidate.xlsx\") \n",
    "data_train = pd.read_excel(\"HW3Atrain.xlsx\")\n",
    "\n",
    "X_train = data_train.copy()\n",
    "X_train = X_train.drop('y', axis=1)\n",
    "Y_train = data_train.copy()\n",
    "Y_train = Y_train.drop('X_0', axis=1)\n",
    "Y_train = Y_train.drop('X_1', axis=1)\n",
    "\n",
    "X_test = data_test.copy()\n",
    "X_test = X_test.drop('y', axis=1)\n",
    "Y_test = data_test.copy()\n",
    "Y_test = Y_test.drop('X_0', axis=1)\n",
    "Y_test = Y_test.drop('X_1', axis=1)\n",
    "\n",
    "\n",
    "x_0_min = min(X_train['X_0'])\n",
    "x_0_max = max(X_train['X_0'])\n",
    "\n",
    "x_1_min = min(X_train['X_1'])\n",
    "x_1_max = max(X_train['X_1'])\n",
    "\n",
    "for i in range(len(X_train['X_0'])):\n",
    "    X_train['X_0'][i] = (X_train['X_0'][i]-x_0_min)/(x_0_max-x_0_min) #formula used for Min-Max\n",
    "    X_train['X_1'][i] = (X_train['X_1'][i]-x_1_min)/(x_1_max-x_1_min) #formula used for Min-Max\n",
    "    \n",
    "for i in range(len(X_test['X_0'])):\n",
    "    X_test['X_0'][i] = (X_test['X_0'][i]-x_0_min)/(x_0_max-x_0_min) #formula used for Min-Max\n",
    "    X_test['X_1'][i] = (X_test['X_1'][i]-x_1_min)/(x_1_max-x_1_min) #formula used for Min-Max\n",
    "'''\n",
    "training_data = []\n",
    "for i in range(len(X_train['X_0'])):\n",
    "    training_data.append([round(X_train['X_0'][i], 2),round(X_train['X_1'][i],2)])\n",
    "    \n",
    "testing_data = []\n",
    "for i in range(len(X_test['X_0'])):\n",
    "    testing_data.append([round(X_test['X_0'][i],2),round(X_test['X_1'][i],2)])\n",
    "\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(Y_train['y'])):\n",
    "    y_train.append([Y_train['y'][i]])\n",
    "    \n",
    "y_test = []\n",
    "\n",
    "for i in range(len(Y_test['y'])):\n",
    "    y_test.append([Y_test['y'][i]])\n",
    "'''\n",
    "\n",
    "training_data = np.empty((0,2), int)\n",
    "for i in range(len(X_train['X_0'])):\n",
    "    training_data = np.append(training_data, np.array([[X_train['X_0'][i],X_train['X_1'][i]]]), axis=0)\n",
    "    \n",
    "testing_data = np.empty((0,2), int)\n",
    "for i in range(len(X_test['X_0'])):\n",
    "    testing_data = np.append(testing_data, np.array([[X_test['X_0'][i],X_test['X_1'][i]]]), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "y_train = np.empty((0,1), int)\n",
    "for i in range(len(Y_train['y'])):\n",
    "    y_train = np.append(y_train, np.array([[Y_train['y'][i]]]), axis=0)\n",
    "\n",
    "y_test = np.empty((0,1), int)\n",
    "for i in range(len(Y_test['y'])):\n",
    "    y_test = np.append(y_test, np.array([[Y_test['y'][i]]]), axis=0)\n",
    "\n",
    "np_testing_y = np.array(y_test)\n",
    "np_testing_x = np.array(testing_data)\n",
    "np_training_x = np.array(training_data)\n",
    "np_training_y = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy-iteration: 53.90%\n",
      "Testing accuracy-iteration: 67.07% Learning rate --> 0.009\n",
      "Confusion matrix ---> TrueOne: 37 TrueZero: 18 FalseOne: 23 FalseZero 4\n",
      "MES:  0.2326626577911186\n",
      "\n",
      "Training accuracy-iteration: 58.78%\n",
      "Testing accuracy-iteration: 74.39% Learning rate --> 0.00873\n",
      "Confusion matrix ---> TrueOne: 40 TrueZero: 21 FalseOne: 20 FalseZero 1\n",
      "MES:  0.20449515944743554\n",
      "\n",
      "Training accuracy-iteration: 70.73%\n",
      "Testing accuracy-iteration: 79.27% Learning rate --> 0.0084681\n",
      "Confusion matrix ---> TrueOne: 40 TrueZero: 25 FalseOne: 16 FalseZero 1\n",
      "MES:  0.19932598547465907\n",
      "\n",
      "Training accuracy-iteration: 72.20%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.008214056999999999\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 25 FalseOne: 16 FalseZero 2\n",
      "MES:  0.1972260601547538\n",
      "\n",
      "Training accuracy-iteration: 73.41%\n",
      "Testing accuracy-iteration: 79.27% Learning rate --> 0.007967635289999999\n",
      "Confusion matrix ---> TrueOne: 40 TrueZero: 25 FalseOne: 16 FalseZero 1\n",
      "MES:  0.1939457296095762\n",
      "\n",
      "Training accuracy-iteration: 74.15%\n",
      "Testing accuracy-iteration: 78.05% Learning rate --> 0.007728606231299998\n",
      "Confusion matrix ---> TrueOne: 40 TrueZero: 24 FalseOne: 17 FalseZero 1\n",
      "MES:  0.19110869525851795\n",
      "\n",
      "Training accuracy-iteration: 74.88%\n",
      "Testing accuracy-iteration: 76.83% Learning rate --> 0.007496748044360998\n",
      "Confusion matrix ---> TrueOne: 40 TrueZero: 23 FalseOne: 18 FalseZero 1\n",
      "MES:  0.18874221664242094\n",
      "\n",
      "Training accuracy-iteration: 76.34%\n",
      "Testing accuracy-iteration: 76.83% Learning rate --> 0.007271845603030167\n",
      "Confusion matrix ---> TrueOne: 40 TrueZero: 23 FalseOne: 18 FalseZero 1\n",
      "MES:  0.18658988935702328\n",
      "\n",
      "Training accuracy-iteration: 76.83%\n",
      "Testing accuracy-iteration: 79.27% Learning rate --> 0.007053690234939262\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 26 FalseOne: 15 FalseZero 2\n",
      "MES:  0.18446850216974145\n",
      "\n",
      "Training accuracy-iteration: 76.59%\n",
      "Testing accuracy-iteration: 80.49% Learning rate --> 0.006842079527891084\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 27 FalseOne: 14 FalseZero 2\n",
      "MES:  0.1822691057483243\n",
      "\n",
      "Training accuracy-iteration: 77.07%\n",
      "Testing accuracy-iteration: 80.49% Learning rate --> 0.0066368171420543515\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 27 FalseOne: 14 FalseZero 2\n",
      "MES:  0.179914108695154\n",
      "\n",
      "Training accuracy-iteration: 78.05%\n",
      "Testing accuracy-iteration: 84.15% Learning rate --> 0.0064377126277927205\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 30 FalseOne: 11 FalseZero 2\n",
      "MES:  0.17733601510700292\n",
      "\n",
      "Training accuracy-iteration: 78.54%\n",
      "Testing accuracy-iteration: 84.15% Learning rate --> 0.0062445812489589385\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 30 FalseOne: 11 FalseZero 2\n",
      "MES:  0.1744761290327749\n",
      "\n",
      "Training accuracy-iteration: 79.02%\n",
      "Testing accuracy-iteration: 85.37% Learning rate --> 0.0060572438114901705\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 31 FalseOne: 10 FalseZero 2\n",
      "MES:  0.17129268017681282\n",
      "\n",
      "Training accuracy-iteration: 81.46%\n",
      "Testing accuracy-iteration: 85.37% Learning rate --> 0.005875526497145465\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 31 FalseOne: 10 FalseZero 2\n",
      "MES:  0.16777341560061015\n",
      "\n",
      "Training accuracy-iteration: 80.98%\n",
      "Testing accuracy-iteration: 85.37% Learning rate --> 0.005699260702231101\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 31 FalseOne: 10 FalseZero 2\n",
      "MES:  0.1639506048348166\n",
      "\n",
      "Training accuracy-iteration: 81.22%\n",
      "Testing accuracy-iteration: 86.59% Learning rate --> 0.0055282828811641675\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 32 FalseOne: 9 FalseZero 2\n",
      "MES:  0.1599148835332683\n",
      "\n",
      "Training accuracy-iteration: 82.44%\n",
      "Testing accuracy-iteration: 89.02% Learning rate --> 0.0053624343947292425\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 34 FalseOne: 7 FalseZero 2\n",
      "MES:  0.15582072432140034\n",
      "\n",
      "Training accuracy-iteration: 82.68%\n",
      "Testing accuracy-iteration: 90.24% Learning rate --> 0.005201561362887365\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 35 FalseOne: 6 FalseZero 2\n",
      "MES:  0.1518742680674078\n",
      "\n",
      "Training accuracy-iteration: 82.68%\n",
      "Testing accuracy-iteration: 91.46% Learning rate --> 0.005045514522000744\n",
      "Confusion matrix ---> TrueOne: 39 TrueZero: 36 FalseOne: 5 FalseZero 2\n",
      "MES:  0.1482985257476465\n",
      "\n",
      "Training accuracy-iteration: 83.66%\n",
      "Testing accuracy-iteration: 86.59% Learning rate --> 0.0048941490863407214\n",
      "Confusion matrix ---> TrueOne: 36 TrueZero: 35 FalseOne: 6 FalseZero 5\n",
      "MES:  0.14528335490637942\n",
      "\n",
      "Training accuracy-iteration: 83.66%\n",
      "Testing accuracy-iteration: 85.37% Learning rate --> 0.0047473246137505\n",
      "Confusion matrix ---> TrueOne: 35 TrueZero: 35 FalseOne: 6 FalseZero 6\n",
      "MES:  0.14294084153393147\n",
      "\n",
      "Training accuracy-iteration: 83.66%\n",
      "Testing accuracy-iteration: 86.59% Learning rate --> 0.004604904875337985\n",
      "Confusion matrix ---> TrueOne: 36 TrueZero: 35 FalseOne: 6 FalseZero 5\n",
      "MES:  0.14128756222938144\n",
      "\n",
      "Training accuracy-iteration: 83.41%\n",
      "Testing accuracy-iteration: 86.59% Learning rate --> 0.004466757729077846\n",
      "Confusion matrix ---> TrueOne: 36 TrueZero: 35 FalseOne: 6 FalseZero 5\n",
      "MES:  0.14025967797819924\n",
      "\n",
      "Training accuracy-iteration: 84.88%\n",
      "Testing accuracy-iteration: 87.80% Learning rate --> 0.00433275499720551\n",
      "Confusion matrix ---> TrueOne: 37 TrueZero: 35 FalseOne: 6 FalseZero 4\n",
      "MES:  0.13974731932242587\n",
      "\n",
      "\n",
      "Average training time for network running 50 iterations with batch size 5 --->2.1402305698394777s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Accuracy-best: 91.46% Learning rate --> 0.005045514522000744\n",
      "TrueOne: 39 TrueZero: 36 FalseOne: 5 FalseZero 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Network_layer:\n",
    "    \n",
    "    def __init__(self, number_input, number_neurons, use_standard_activation):\n",
    "        #self.size = size\n",
    "        #self.weights = (np.random.rand(number_input,number_neurons)*2) - 1\n",
    "        self.weights = np.random.rand(number_input,number_neurons)\n",
    "        self.bias = np.zeros(number_neurons)\n",
    "        self.last_activation = None\n",
    "        self.use_standard_activation = use_standard_activation\n",
    "        self.error = None\n",
    "        self.delta = None\n",
    "        \n",
    "    def activate(self, x):\n",
    "        r = np.dot(x, self.weights) + self.bias\n",
    "        self.last_activation = self.activation(r)\n",
    "            \n",
    "        return self.last_activation\n",
    "\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def activation(self, x):\n",
    "        #relu\n",
    "        if self.use_standard_activation:\n",
    "            x[x<0] = 0\n",
    "            return x\n",
    "        #tanh\n",
    "        return self.tanh(x)\n",
    "    \n",
    "    def activation_derivative(self, x):\n",
    "        #relu derivative\n",
    "        if self.use_standard_activation:\n",
    "            x[x>0] = 1\n",
    "            x[x<0] = 0\n",
    "            return x\n",
    "        #tanh derivative\n",
    "        return 1.0 - np.tanh(x)**2\n",
    "    \n",
    "\n",
    "class Neaural_net:\n",
    "    layers = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "    \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.activate(X)\n",
    "        return X\n",
    "\n",
    "    def softmax(self,X):\n",
    "        exps = np.exp(X)\n",
    "        return exps / np.sum(exps)\n",
    "    \n",
    "    def cross_entropy(self, X,y):\n",
    "        m = y.shape[0]\n",
    "        p = self.softmax(X)\n",
    "        \n",
    "        likelihood = -np.log(p[range(m), y.argmax(axis=1)])\n",
    "        loss = np.sum(likelihood) / m\n",
    "        return loss\n",
    "        \n",
    "    def logloss(self, true_label, predicted, eps=1e-15):\n",
    "        p = np.clip(predicted, eps, 1 - eps)\n",
    "        if true_label == 1:\n",
    "            return -math.log(p)\n",
    "        else:\n",
    "            return -math.log(1 - p) \n",
    "        \n",
    "    def mae(self, targets, predictions):\n",
    "        differences = predictions - targets\n",
    "        absolute_differences = np.absolute(differences)\n",
    "        mean_absolute_differences = absolute_differences.mean()\n",
    "        return mean_absolute_differences\n",
    "        \n",
    "    def mean_squared_error(self, actual, predicted):\n",
    "        sum_square_error = 0.0\n",
    "        for i in range(len(actual)):\n",
    "            sum_square_error += (actual[i] - predicted[i])**2.0\n",
    "        mean_square_error = sum_square_error / len(actual)\n",
    "\n",
    "        return mean_square_error\n",
    "        \n",
    "    def checkPrediction(self, y, pred):\n",
    "        pred = np.around(pred)\n",
    "        if pred == y:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "               \n",
    "        \n",
    "    def backpropagation(self, X, y, learning_rate):\n",
    "        output = self.feed_forward(X)\n",
    "        average_activation = None\n",
    "        correct_predictions = 0\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            layer = self.layers[i]\n",
    "            all_deltas = []\n",
    "            last_activations = []\n",
    "            for j in range(len(output)):\n",
    "                if layer == self.layers[-1]:\n",
    "                    layer.error =  y[j] - output[j]\n",
    "                    all_deltas.append(layer.error * layer.activation_derivative(output[j]))\n",
    "                    last_activations.append(layer.activation_derivative(output[j]))\n",
    "                    correct_predictions = correct_predictions + self.checkPrediction(y[j], output[j])\n",
    "                else:\n",
    "                    next_layer = self.layers[i + 1]\n",
    "                    layer.error = np.dot(next_layer.weights, next_layer.delta)\n",
    "                    all_deltas.append(layer.error * layer.activation_derivative(layer.last_activation[j]))\n",
    "                    last_activations.append(layer.activation_derivative(layer.last_activation[j]))\n",
    "                    \n",
    "            average_delta = sum(all_deltas)/float(len(output))\n",
    "            average_activation = sum(last_activations)/float(len(output))\n",
    "            layer.delta = average_delta\n",
    "    \n",
    "        # Update the weights\n",
    "        for j in range(len(output)):\n",
    "            for i in range(len(self.layers)):\n",
    "                layer = self.layers[i]\n",
    "                input_to_use = np.atleast_2d(X[j] if i == 0 else self.layers[i - 1].last_activation[j])\n",
    "                layer.weights += layer.delta * input_to_use.T * learning_rate\n",
    "        return correct_predictions\n",
    "            \n",
    "    \n",
    "    \n",
    "    def get_batch(self, inputs, targets, batchsize, shuffle=False):\n",
    "        assert len(inputs) == len(targets)\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(len(inputs))\n",
    "        for start in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "            if shuffle:\n",
    "                excerpt = indices[start:start + batchsize]\n",
    "            else:\n",
    "                excerpt = slice(start, start + batchsize)\n",
    "            yield inputs[excerpt], targets[excerpt] \n",
    "\n",
    "            \n",
    "    def train(self, X, y, learning_rate, max_epochs, batchsize):\n",
    "        mses = []\n",
    "        training_accuracy = []\n",
    "        for i in range(max_epochs):\n",
    "            correct_per_epoch = 0\n",
    "            for x_batch,y_batch in self.get_batch(X,y,batchsize=batchsize,shuffle=False):\n",
    "                correct_predictions_batch = self.backpropagation(x_batch,y_batch, learning_rate)\n",
    "                correct_per_epoch = correct_per_epoch + correct_predictions_batch\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                mse = np.mean(np.square(y - NN.feed_forward(X)))\n",
    "                mses.append(mse)\n",
    "                training_accuracy.append((correct_per_epoch/len(X))*100)\n",
    "        return mses, training_accuracy \n",
    "    \n",
    "    \n",
    "    \n",
    "    def test(self, X, y_true):\n",
    "        correct = 0\n",
    "        TT = 0 \n",
    "        TF = 0\n",
    "        FT = 0\n",
    "        FF = 0\n",
    "        mses = []\n",
    "        forward_passes = []\n",
    "        y_truth_values = []\n",
    "        for i in range(len(X)):\n",
    "            forward_pass = self.feed_forward(X[i])\n",
    "            forward_passes.append(forward_pass)\n",
    "            pred = np.around(forward_pass)\n",
    "            y = y_true[i]\n",
    "            y_truth_values.append(y)\n",
    "            if pred == y:\n",
    "                correct = correct + 1\n",
    "            if pred == 1 and y == 1:\n",
    "                TT = TT + 1\n",
    "            if pred == 1 and y == 0:\n",
    "                FT = FT + 1\n",
    "            if pred == 0 and y == 1:\n",
    "                FF = FF + 1\n",
    "            if pred == 0 and y == 0:\n",
    "                TF = TF + 1\n",
    "            confusion = [TT, TF, FT, FF]\n",
    "        mse = np.mean(np.square(np.array(y_truth_values) - np.array(forward_passes)))\n",
    "        mses.append(mse)\n",
    "        return correct/len(X), confusion, mses\n",
    "\n",
    "def should_break(last_mse, mses, lowest_mse):\n",
    "    stop = False\n",
    "    mse_same = True\n",
    "    for i in range(len(last_mse)):\n",
    "        if round(last_mse[i],4) != round(mses[0],4):\n",
    "            mse_same = False\n",
    "    if mse_same:\n",
    "        print(\"MSE has converged!\")\n",
    "        stop = True\n",
    "    if round(mses[0], 3) < 0.07:\n",
    "        print(\"Error is sufficiently low!\")\n",
    "        stop = True\n",
    "    if round(mses[0],4) - lowest_mse > 0.05:\n",
    "        print(\"MSE increased!\")\n",
    "        stop = True\n",
    "    return stop\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_training(NN, learning_rate = 0.009, batchsize = 5, number_test = 25, number_epoc = 50):\n",
    "    # Train the neural networks\n",
    "    accuracy = []\n",
    "    iteration = []\n",
    "    total_error = []\n",
    "    total_mses = []\n",
    "    total_training_accuracy = []\n",
    "    last_mse = [0,0,0,0,0]\n",
    "    a = 0\n",
    "    total_time = 0\n",
    "    max_accuracy = 0\n",
    "    best_NN = copy.copy(NN)\n",
    "    best_confusion = [0,0,0,0]\n",
    "    best_learning_rate = learning_rate\n",
    "    recall = []\n",
    "    precision = []\n",
    "    lowest_mse = 100\n",
    "    \n",
    "    for i in range(1,number_test+1):\n",
    "        start = time.time()\n",
    "        errors, training_accuracy = NN.train(np_training_x, np_training_y, learning_rate, number_epoc, batchsize)\n",
    "        end = time.time()\n",
    "        total_time = total_time + (end-start)\n",
    "        total_error.append(errors)\n",
    "        total_training_accuracy.append(training_accuracy)\n",
    "        iteration.append(i*number_epoc)\n",
    "        accuracy_one, confusion, mses = NN.test(np_testing_x, np_testing_y)\n",
    "        total_mses.append(mses)\n",
    "        last_mse[a] = round(mses[0],4)\n",
    "        a = a + 1\n",
    "        if a > 4:\n",
    "            a = 0\n",
    "\n",
    "        if(accuracy_one > max_accuracy):\n",
    "            max_accuracy = copy.copy(accuracy_one)\n",
    "            best_NN = copy.deepcopy(NN)\n",
    "            best_confusion = copy.copy(confusion)\n",
    "            best_learning_rate = copy.copy(learning_rate)\n",
    "        if mses[0] < lowest_mse:\n",
    "            lowest_mse = mses[0]\n",
    "        print('Training accuracy-iteration: %.2f%%' % (training_accuracy[-1]))\n",
    "        print('Testing accuracy-iteration: %.2f%%' % (accuracy_one*100), \"Learning rate --> \"+ str(learning_rate))\n",
    "        print('Confusion matrix ---> TrueOne:',confusion[0] ,'TrueZero:',confusion[1], 'FalseOne:',confusion[2] , 'FalseZero',confusion[3] )\n",
    "        print(\"MES: \", mses[0])\n",
    "        print()\n",
    "        #recall_tmp = round(confusion[0]/(confusion[0]+confusion[3]), 2)\n",
    "        #precision_tmp = round(confusion[0]/(confusion[0]+confusion[2]), 2)\n",
    "        #recall.append(recall_tmp)\n",
    "        #print('Recall=', recall_tmp)\n",
    "        #precision.append(precision_tmp)\n",
    "        #print('Precision=', precision_tmp)\n",
    "        accuracy.append(accuracy_one*100)\n",
    "        if should_break(last_mse, mses, lowest_mse):\n",
    "            break;\n",
    "        learning_rate = learning_rate*0.97\n",
    "        \n",
    "    print()\n",
    "    print(\"Average training time for network running \" + str(number_epoc) + \" iterations with batch size \" + str(batchsize) + \" --->\" + str(total_time/number_test)+ \"s\")\n",
    "    plt.plot(iteration,accuracy, label='Validation accuracy')\n",
    "    #plt.plot(iteration, total_error, label='Mean squared error for training set')\n",
    "    #plt.plot(iteration, total_mses, label='Mean squared error for validation set')\n",
    "    plt.plot(iteration, total_training_accuracy, label='Training accuracy')\n",
    "    #plt.plot(iteration, recall, label='Recall')\n",
    "    #plt.plot(iteration, precision, label='Precision')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('Accuracy & MSE(*100)')\n",
    "    plt.axis((number_epoc,number_epoc*number_test,0,100))\n",
    "    plt.title('')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    accuracy_one, confusion, mses = best_NN.test(np_testing_x, np_testing_y)\n",
    "    print(\"------------------------\")\n",
    "    print('Accuracy-best: %.2f%%' % (accuracy_one*100), \"Learning rate --> \"+ str(best_learning_rate))\n",
    "    print('TrueOne:',confusion[0] ,'TrueZero:',confusion[1], 'FalseOne:',confusion[2] , 'FalseZero',confusion[3] )\n",
    "    print()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def init_net(hidden_layers):\n",
    "    NN = Neaural_net()\n",
    "    NN.add_layer(Network_layer(2, 10, False))\n",
    "    for i in range(hidden_layers - 1):\n",
    "        NN.add_layer(Network_layer(10, 10, False))\n",
    "    NN.add_layer(Network_layer(10,1, False))\n",
    "    return NN\n",
    "\n",
    "\n",
    "NN = init_net(2)\n",
    "run_training(NN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (10 points) Activation and Loss functions. \n",
    "Please choose suitable activation functions φ(0), φ(1), φ(2) and a suitable Loss function to perform the task. Report and justify your choices in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(self, x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(self, x)\n",
    "    return 1.0 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use the tanh activation function in all the layers, we tried to use sigmoid and ReLu but we got the best results using ReLu. \n",
    "\n",
    "To calculate the error we subtracted the output from our net from the true value from the set. Then we used Mean Squared error to determine the net's accuracy. $$MSE = \\frac{1}{n}\\sum_{i=1}^{n} (y_i-\\bar{y}_i)^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (10 points) Learning rate, batch size, initialization. \n",
    "Please choose a suitable learning rate, batch size, initialization of the parameter values, and any other setting you may need. Discuss and justify your choices in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started with the learning rate as 0.009 and after each test the learning rate was reduced by 1%. We tried various batch sizes, what worked best was relatively small batch sizes so we ended using \n",
    "$$batchsize=5$$\n",
    "We initialized our weights as a random number from 0 to 1 and our biases as 0. We read that it is best to initialize biases as zero, it also didn´t give good results when we tried random to initilaze the biases. We knew that using random initialization for the weights is better than using zeroes. We tried some other initilizations such as from 0 to 0.5 or -0.5 to 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (10 points) Training. \n",
    "Make plots with the loss function computed over the training set and over the validation set. Stop the training when the error is small enough. Justify your stopping criterium. Report the final accuracy obtained and the confusion matrix on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de3gV5b328e9PQHEjKEV0IyDQbhQ5hIDh3AqUgpxEtopAFVGsdKuobbco2gpYvd6ylRal2oqtJZSXDbg9tLyAVUtJUYqVoMAOUJBqgIgtIZUIGEqA3/vHmixXwsphIJOE5P5c17pYM/OsmWcOcPPM4Rlzd0RERCrqrOqugIiInFkUHCIiEoqCQ0REQlFwiIhIKAoOEREJRcEhIiKhRBYcZvYrM9tnZlmlTDczm2tmO81ss5l1j6ouIiJSeaJscaQDQ8uYPgxoH3wmAz+PsC4iIlJJIgsOd18D/KOMItcCv/aYd4ALzKxFVPUREZHKUb8al90S2JMwnBOM+6RkQTObTKxVQqNGja7s0KFDlVRQRKS22LBhw353b14Z86rO4LAk45L2f+LuzwPPA6SlpXlmZmaU9RIRqXXMbFdlzas676rKAVonDLcC9lZTXUREpIKqMziWAbcEd1f1BvLd/aTTVCIiUrNEdqrKzBYDA4ALzSwHmAE0AHD354CVwHBgJ/A5cFtUdRERkcoTWXC4+/hypjtwd1TLl+pXWFhITk4OR44cqe6qiNQZDRs2pFWrVjRo0CCyZVTnxXGp5XJycmjcuDFt27bFLNm9ECJSmdydvLw8cnJyaNeuXWTLUZcjEpkjR47QrFkzhYZIFTEzmjVrFnkrX8EhkVJoiFStqvg7p+AQEZFQFBxSq5kZEyZMiA8fO3aM5s2bM3LkyGqsVfUZMGAANeEB2qlTp9KpUyemTp16Sr/fuHEjK1euDP27vXv3csMNN5Rbbvjw4Rw4cOBUqnZannrqKT7//PMqX25YCg6p1Ro1akRWVhYFBQUAvPnmm7Rs2bKaa1W5jh07Vi3Lqehyk5WbN28e7733Hk8++eQpzaOs4CirXpdccgkvvfRSuctbuXIlF1xwQYXqVpkUHCI1xLBhw1ixYgUAixcvZvz4L+4UP3z4MJMmTaJHjx5069aN3/72twBkZ2fzta99je7du9O9e3f+9Kc/AZCRkcGAAQO44YYb6NChAzfddBOxO8uLmzt3Lh07diQlJYVx48YBkJeXx5AhQ+jWrRvf/va3adOmDfv37yc7O5vOnTvHfzt79mxmzpwJwC9+8Qt69OhB165duf766+P/qNx6661873vfY+DAgTz44IOlrkdBQQHjxo0jJSWFsWPHxgO0pA0bNtC/f3+uvPJKrr76aj75JPYs7oABA3j44Yfp378/Tz/99EnL/cc//sHo0aNJSUmhd+/ebN68GYCZM2cyefJkhgwZwi233FJsWaNGjeLw4cP06tWLpUuXsmvXLgYNGkRKSgqDBg1i9+7dSdexyNGjR5k+fTpLly4lNTWVpUuXnrS80vZf4rZOT0/nuuuuY+jQobRv354HHnggvoy2bdvG980VV1zBHXfcQadOnRgyZEh8G65fv56UlBT69OnD1KlTi+3DIp988glXXXUVqampdO7cmbfeeguAN954gz59+tC9e3fGjBnDoUOHmDt3Lnv37mXgwIEMHDgw6X6qMdz9jPpceeWVLmeGrVu3xr/PXJblNz73p0r9zFyWVW4dGjVq5Js2bfLrr7/eCwoKvGvXrr569WofMWKEu7s/9NBDvnDhQnd3//TTT719+/Z+6NAhP3z4sBcUFLi7+44dO7zouFu9erU3adLE9+zZ48ePH/fevXv7W2+9ddJyW7Ro4UeOHInP1939nnvu8UcffdTd3ZcvX+6A5+bm+kcffeSdOnWK//bJJ5/0GTNmuLv7/v374+O///3v+9y5c93dfeLEiT5ixAg/duxYmevx4x//2G+77TZ3d9+0aZPXq1fP169fX6yuR48e9T59+vi+ffvc3X3JkiXx3/Tv39/vvPPOeNmSy50yZYrPnDnT3d1XrVrlXbt2dXf3GTNmePfu3f3zzz8vdb8UGTlypKenp7u7+wsvvODXXntt0mUlmj9/vt99993x4ZLLK23/JW7r+fPne7t27fzAgQNeUFDgl156qe/evdvd3du0aRPfN/Xq1fP333/f3d3HjBkT386dOnXytWvXurv7gw8+WGwfFpk9e7Y//vjj7u5+7Ngx/+yzzzw3N9e/9rWv+aFDh9zdfdasWfHjomi5pyvx714RINMr6d9hPcchtV5KSgrZ2dksXryY4cOHF5v2xhtvsGzZMmbPng3EbiHevXs3l1xyCVOmTGHjxo3Uq1ePHTt2xH/Ts2dPWrVqBUBqairZ2dl89atfPWmZN910E6NHj2b06NEArFmzhldeeQWAESNG0LRp03LrnpWVxQ9+8AMOHDjAoUOHuPrqq+PTxowZQ7169cpcjzVr1nDvvffG65SSknLSMrZv305WVhaDBw8G4Pjx47Ro8cUbDsaOHVusfOJy3377bV5++WUAvv71r5OXl0d+fj4Qa1mce+655a7junXr4ttlwoQJxf7nn7is8iQur7CwsNT9l2jQoEGcf/75AHTs2JFdu3bRunXrYmXatWtHamoqAFdeeSXZ2dkcOHCAgwcP0rdvXwC++c1vsnz58pPm36NHDyZNmkRhYSGjR48mNTWVP/7xj2zdupV+/foBsRZUnz59KrSONYWCQ6rEjGs6VevyR40axf33309GRgZ5eXnx8e7Oyy+/zOWXX16s/MyZM7n44ovZtGkTJ06coGHDhvFp55xzTvx7vXr1kp5TX7FiBWvWrGHZsmU89thjbNmyBUh+q2T9+vU5ceJEfDjxHvxbb72V3/zmN3Tt2pX09HQyMjLi0xo1alTuepS2zETuTqdOnVi3bl3S6YnLSbbc0pZX8ncVlVjfMPNILDtnzpxS91+iiuzLkmUKCgqSrncyV111FWvWrGHFihVMmDCBqVOn0rRpUwYPHszixYsrumo1jq5xSJ0wadIkpk+fTpcuXYqNv/rqq/npT38a/4fg/fffByA/P58WLVpw1llnsXDhQo4fP17hZZ04cYI9e/YwcOBAnnjiiXhr4aqrrmLRokUAvPbaa3z66acAXHzxxezbt4+8vDz++c9/Fvuf68GDB2nRogWFhYXx3yZT2nokLjMrKyt+DSLR5ZdfTm5ubjw4CgsL40FXnsT5Z2RkcOGFF9KkSZMK/bZI3759WbJkCQCLFi06qfWWTOPGjTl48GCp009n/1VE06ZNady4Me+88w5AvP4l7dq1i4suuog77riD22+/nffee4/evXuzdu1adu7cCcDnn38ebxGVt141hYJD6oRWrVpx3333nTT+kUceobCwkJSUFDp37swjjzwCwF133cWCBQvo3bs3O3bsCPU/3+PHj3PzzTfTpUsXunXrxne/+10uuOACZsyYwZo1a+jevTtvvPEGl156KQANGjRg+vTp9OrVi5EjR5L4orLHHnuMXr16MXjwYMp6gVlp63HnnXdy6NAhUlJSeOKJJ+jZs+dJvz377LN56aWXePDBB+natSupqanxi8nlmTlzJpmZmaSkpDBt2jQWLFhQ4e1UZO7cucyfP5+UlBQWLlzI008/Xe5vBg4cyNatW+MXx0s6nf1XUS+88AKTJ0+mT58+uHv8lFeijIwMUlNT6datGy+//DL33XcfzZs3Jz09nfHjx8dvKvjLX/4CwOTJkxk2bFiNvzhuFW1y1RR6kdOZY9u2bVxxxRXVXY0aq23btmRmZnLhhRdWd1XkFBw6dIjzzjsPgFmzZvHJJ59UKPSqQrK/e2a2wd3TKmP+usYhInIKVqxYwY9+9COOHTtGmzZtSE9Pr+4qVRkFh0g1yc7Oru4qyGkYO3bsSXec1RW6xiEiIqEoOEREJBQFh4iIhKLgEBGRUBQcUqupW/Xiaku36mFlZGTE9/myZcuYNWtW0nJFt9eW5sCBA/zsZz+LD1e0m/bKlpGRUeFnbaKgu6qkVkvsVv3cc8+ttd2q168f/V/lksup6HKTlZs3bx65ubnFuvMIO49TNWrUKEaNGnVKvy0KjrvuuguoeDftlS0jI4Pzzjsv3ldWVVOLQ2o9dateu7pVB+jVq1exblEGDBjAhg0bePfdd+nbty/dunWjb9++bN++/aR1TU9PZ8qUKQB89NFH9OnThx49esSftofYw32DBg2ie/fudOnSJb49p02bxl//+ldSU1OZOnVqsX135MgRbrvttniPAatXr44vr7Tu2xNNmzYtfszcf//9AOTm5nL99dfTo0cPevTowdq1a8nOzua5555jzpw5pKamxrtqr1KV1c1uVX3UrfqZo1jXzisfdP/V8Mr9rHyw3DqoW/Xa2a36T37yE58+fbq7u+/du9fbt2/v7u75+fleWFjo7u5vvvmmX3fdde7uxfZ5Ypfs11xzjS9YsMDd3Z955pl4vQoLCz0/P9/d3XNzc/0rX/mKnzhx4qR9lTg8e/Zsv/XWW93dfdu2bd66dWsvKCgos/v2Inl5eX7ZZZf5iRMn3P2LY2b8+PHx42vXrl3eoUOH+PZ98sknk25bd3WrLnLa1K167etW/cYbb2Tw4ME8+uijvPjii4wZMwaIdW44ceJEPvjgA8yMwsLCMpe9du3aeP0nTJgQb9m4Ow8//DBr1qzhrLPO4uOPP+bvf/97mfN6++23ueeeewDo0KEDbdq0iR835XXf3qRJExo2bMi3vvUtRowYEb8e8/vf/56tW7fGy3322Wc1ohNEBYdUjWHJL0ZWFXWrXjo/A7tVb9myJc2aNWPz5s0sXbqUefPmAbHOHgcOHMirr75KdnY2AwYMCLW8IosWLSI3N5cNGzbQoEED2rZtW2y/JJNsWxQp75ipX78+7777LqtWrWLJkiU888wz/OEPf+DEiROsW7euQgFclXSNQ+oEdateu7pVBxg3bhxPPPEE+fn58f2an58fv/mhIn1H9evXr9iyi+Tn53PRRRfRoEEDVq9eza5du4Cyuz1P3BY7duxg9+7dSYM8mUOHDpGfn8/w4cN56qmn2LhxIwBDhgzhmWeeiZcrGl/d3a8rOKROULfqtatbdYAbbriBJUuWcOONN8bHPfDAAzz00EP069evQmH/9NNP8+yzz9KjR4/4KTaAm266iczMTNLS0li0aFF82zdr1ox+/frRuXPnk24lvuuuuzh+/DhdunRh7NixpKenV/iusYMHDzJy5EhSUlLo378/c+bMAWLbpmj7duzYkeeeew6Aa665hldffbXaLo6rW3WJjLpVL5u6VZeoRN2tulocIiISii6Oi1QTdasuZyq1OCRSZ9qpUJEzXVX8nVNwSGQaNmxIXl6ewkOkirg7eXl5xW4fj4JOVUlkWrVqRU5ODrm5udVdFZE6o2HDhvEHVKOi4JDINGjQgHbt2lV3NUSkkulUlYiIhBJpcJjZUDPbbmY7zWxakumXmtlqM3vfzDab2fBk8xERkZojsuAws3rAs8AwoCMw3sw6lij2A+BFd+8GjAN+hoiI1GhRtjh6Ajvd/UN3PwosAa4tUcaBoo5tzgf2RlgfERGpBFEGR0tgT8JwTjAu0UzgZjPLAVYC9ySbkZlNNrNMM8vUHToiItUryuBI1pdzyRv6xwPp7t4KGA4sNLOT6uTuz7t7mrunNW/ePIKqiohIRUUZHDlA64ThVpx8Kup24EUAd18HNATU45uISA0WZXCsB9qbWTszO5vYxe9lJcrsBgYBmNkVxIJD56JERGqwyILD3Y8BU4DXgW3E7p7aYmY/NLNRQbH/BO4ws03AYuBWV/8UIiI1WqRPjrv7SmIXvRPHTU/4vhXoF2UdRESkcunJcRERCUXBISIioSg4REQkFAWHiIiEouAQEZFQFBwiIhKKgkNEREJRcIiISCgKDhERCUXBISIioSg4REQkFAWHiIiEouAQEZFQFBwiIhKKgkNEREJRcIiISCgKDhERCUXBISIioSg4REQkFAWHiIiEouAQEZFQFBwiIhKKgkNEREJRcIiISCgKDhERCUXBISIioSg4REQkFAWHiIiEouAQEZFQFBwiIhKKgkNEREJRcIiISCgKDhERCUXBISIioUQaHGY21My2m9lOM5tWSpkbzWyrmW0xs/+Osj4iInL66kc1YzOrBzwLDAZygPVmtszdtyaUaQ88BPRz90/N7KKo6iMiIpUjyhZHT2Cnu3/o7keBJcC1JcrcATzr7p8CuPu+COsjIiKVIMrgaAnsSRjOCcYlugy4zMzWmtk7ZjY02YzMbLKZZZpZZm5ubkTVFRGRiogyOCzJOC8xXB9oDwwAxgO/NLMLTvqR+/Punubuac2bN6/0ioqISMVFGRw5QOuE4VbA3iRlfuvuhe7+EbCdWJCIiEgNFWVwrAfam1k7MzsbGAcsK1HmN8BAADO7kNipqw8jrJOIiJymyILD3Y8BU4DXgW3Ai+6+xcx+aGajgmKvA3lmthVYDUx197yo6iQiIqfP3EtedqjZ0tLSPDMzs7qrISJyRjGzDe6eVhnz0pPjIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqEoOEREJBQFh4iIhKLgEBGRUMoMDjO7OeF7vxLTpkRVKRERqbnKa3F8L+H7T0tMm1TJdRERkTNAecFhpXxPNiwiInVAecHhpXxPNiwiInVAee8c72Bmm4m1Lr4SfCcY/nKkNRMRkRqpvOC4okpqISIiZ4wyg8PddyUOm1kz4Cpgt7tviLJiIiJSM5V3O+5yM+scfG8BZBG7m2qhmX2nCuonIiI1THkXx9u5e1bw/TbgTXe/BuiFbscVEamTyguOwoTvg4CVAO5+EDgRVaVERKTmKu/i+B4zuwfIAboDvwMws3OBBhHXTUREaqDyWhy3A52AW4Gx7n4gGN8bmB9hvUREpIYq766qfcB/JBm/GlgdVaVERKTmKjM4zGxZWdPdfVTlVkdERGq68q5x9AH2AIuBP6P+qURE6rzyguNfgcHAeOCbwApgsbtvibpiIiJSM5V5cdzdj7v779x9IrEL4juBjOBOKxERqYPKa3FgZucAI4i1OtoCc4FXoq2WiIjUVOVdHF8AdAZeAx5NeIpcRETqqPJaHBOAw8BlwL1m8WvjBri7N4mwbiIiUgOV9xxHeQ8IiohIHaNgEBGRUBQcIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqFEGhxmNtTMtpvZTjObVka5G8zMzSwtyvqIiMjpiyw4zKwe8CwwDOgIjDezjknKNQbuJdb7roiI1HBRtjh6Ajvd/UN3PwosAa5NUu4x4AngSIR1ERGRShJlcLQk9i6PIjnBuDgz6wa0dvflZc3IzCabWaaZZebm5lZ+TUVEpMKiDI5kL33y+ESzs4A5wH+WNyN3f97d09w9rXnz5pVYRRERCSvK4MgBWicMtwL2Jgw3JtbzboaZZRN738cyXSAXEanZogyO9UB7M2tnZmcD44D4O8zdPd/dL3T3tu7eFngHGOXumRHWSURETlNkweHux4ApwOvANuBFd99iZj80s1FRLVdERKJV7hsAT4e7rwRWlhg3vZSyA6Ksi4iIVA49OS4iIqEoOEREJBQFh4iIhKLgEBGRUBQcIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqEoOEREJBQFh4iIhKLgEBGRUBQcIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqEoOEREJBQFh4iIhKLgEBGRUBQcIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqEoOEREJBQFh4iIhKLgEBGRUBQcIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqEoOEREJJRIg8PMhprZdjPbaWbTkkz/npltNbPNZrbKzNpEWR8RETl9kQWHmdUDngWGAR2B8WbWsUSx94E0d08BXgKeiKo+IiJSOaJscfQEdrr7h+5+FFgCXJtYwN1Xu/vnweA7QKsI6yMiIpUgyuBoCexJGM4JxpXmduC1ZBPMbLKZZZpZZm5ubiVWUUREwooyOCzJOE9a0OxmIA14Mtl0d3/e3dPcPa158+aVWEUREQmrfoTzzgFaJwy3AvaWLGRm3wC+D/R3939GWB8REakEUbY41gPtzaydmZ0NjAOWJRYws27APGCUu++LsC4iIlJJIgsOdz8GTAFeB7YBL7r7FjP7oZmNCoo9CZwH/I+ZbTSzZaXMTkREaogoT1Xh7iuBlSXGTU/4/o0oly8iIpVPT46LiEgoCg4REQlFwSEiIqEoOEREJBQFh4iIhKLgEBGRUBQcIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqEoOEREJBQFh4iIhKLgEBGRUBQcIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqEoOEREJBQFh4iIhKLgEBGRUBQcIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqEoOEREJBQFh4iIhKLgEBGRUBQcIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqFEGhxmNtTMtpvZTjOblmT6OWa2NJj+ZzNrG2V9RETk9EUWHGZWD3gWGAZ0BMabWccSxW4HPnX3fwPmAP8VVX1ERKRyRNni6AnsdPcP3f0osAS4tkSZa4EFwfeXgEFmZhHWSURETlP9COfdEtiTMJwD9CqtjLsfM7N8oBmwP7GQmU0GJgeDh8xseyQ1rhkupMT6C6Dtkoy2SXLaLsldXlkzijI4krUc/BTK4O7PA89XRqVqOjPLdPe06q5HTaPtcjJtk+S0XZIzs8zKmleUp6pygNYJw62AvaWVMbP6wPnAPyKsk4iInKYog2M90N7M2pnZ2cA4YFmJMsuAicH3G4A/uPtJLQ4REak5IjtVFVyzmAK8DtQDfuXuW8zsh0Cmuy8DXgAWmtlOYi2NcVHV5wxSJ07JnQJtl5NpmySn7ZJcpW0X03/wRUQkDD05LiIioSg4REQkFAVHFTKz1ma22sy2mdkWM7svGP8lM3vTzD4I/mwajDczmxt0ybLZzLpX7xpEy8zqmdn7ZrY8GG4XdEXzQdA1zdnB+DrTVY2ZXWBmL5nZX4Ljpk9dP17M7LvB358sM1tsZg3r4rFiZr8ys31mlpUwLvSxYWYTg/IfmNnEZMsqScFRtY4B/+nuVwC9gbuDblimAavcvT2wKhiGWHct7YPPZODnVV/lKnUfsC1h+L+AOcF2+ZRYFzVQt7qqeRr4nbt3ALoS2z519ngxs5bAvUCau3cmduPNOOrmsZIODC0xLtSxYWZfAmYQezi7JzCjKGzK5O76VNMH+C0wGNgOtAjGtQC2B9/nAeMTysfL1bYPsed8VgFfB5YTezh0P1A/mN4HeD34/jrQJ/hePyhn1b0OEWyTJsBHJdetLh8vfNHbxJeCfb8cuLquHitAWyDrVI8NYDwwL2F8sXKlfdTiqCZBk7kb8GfgYnf/BCD486KgWLJuW1pWXS2r1FPAA8CJYLgZcMDdjwXDieterKsaoKirmtrmy0AuMD84hfdLM2tEHT5e3P1jYDawG/iE2L7fgI6VImGPjVM6ZhQc1cDMzgNeBr7j7p+VVTTJuFp3/7SZjQT2ufuGxNFJinoFptUm9YHuwM/dvRtwmC9OPSRT67dLcBrlWqAdcAnQiNhpmJLq2rFSntK2wyltHwVHFTOzBsRCY5G7vxKM/ruZtQimtwD2BeMr0m1LbdAPGGVm2cR6Uf46sRbIBUFXNFB83etKVzU5QI67/zkYfolYkNTl4+UbwEfunuvuhcArQF90rBQJe2yc0jGj4KhCQZfxLwDb3P0nCZMSu16ZSOzaR9H4W4I7InoD+UXN0NrE3R9y91bu3pbYhc4/uPtNwGpiXdHAydul1ndV4+5/A/aYWVGvpoOArdTt42U30NvM/iX4+1S0Ter0sZIg7LHxOjDEzJoGrbkhwbiyVffFnbr0Ab5KrBm4GdgYfIYTO+e6Cvgg+PNLQXkj9jKsvwL/S+xOkmpfj4i30QBgefD9y8C7wE7gf4BzgvENg+GdwfQvV3e9I9weqUBmcMz8Bmha148X4FHgL0AWsBA4py4eK8BiYtd5Com1HG4/lWMDmBRsn53AbRVZtrocERGRUHSqSkREQlFwiIhIKAoOEREJRcEhIiKhKDhERCQUBYfUSGbWzMw2Bp+/mdnHCcNnV3Ae8xOegSitzN1mdlMl1fltM0s1s7PMrKwnvE9l3pPM7F8ThstdN5Go6HZcqfHMbCZwyN1nlxhvxI7hE0l/WMXM7G1gCrHnC/a7+wUhf1/P3Y+XNW9333j6NRU5PWpxyBnFzP4teA/Dc8B7QAsze97MMoN3NExPKFvUAqhvZgfMbJaZbTKzdWZ2UVDmcTP7TkL5WWb2rpltN7O+wfhGZvZy8NvFwbJSy6jmLKBx0Dr6dTCPicF8N5rZz4JWSVG9Hjezd4GeZvaoma0vWsfgSd+xxB4EXFrU4ipat2DeN5vZ/wa/+T/BuLLWeVxQdpOZra7kXSR1gIJDzkQdgRfcvZvHekud5u5pxN5XMdhi7zgp6Xzgj+7eFVhH7GnZZMzdewJTgaIQugf4W/DbWcR6NS7LNOCgu6e6+y1m1hn4d6Cvu6cS67xwXEK93nP3nu6+Dnja3XsAXYJpQ919KbFeBsYG8zwar6xZK+BxYGBQr34W6zSyrHWeAQwKxv97OesichIFh5yJ/uru6xOGx5vZe8RaIFcQC5aSCtz9teD7BmLvMUjmlSRlvkqs80XcfROwJWR9vwH0ADLNbCPQH/hKMO0o8GpC2UFB62NTUK5TOfPuRaz/pf0e6/Tvv4GrgmmlrfNa4Ndm9i30b4CcgvrlFxGpcQ4XfTGz9sTeHNjT3Q+Y2f8l1j9RSUcTvh+n9GP/n0nKJOt6OgwDfuXujxQbGeuttcCLOhMy+xfgGaC7u39sZo+TfF1Kzrs0pa3zHcQCZySwycxS3P3TCq+N1Hn634ac6ZoAB4HPLNaN9NURLONt4EYAM+tC8hZNnAcvFLIvuvn+PXCjmV0YjG9mZpcm+em5xF5ktd/MGgPXJ0w7CDRO8pt3gIHBPItOgf2xnPX5sru/AzxC7DWrteplT/XrV54AAADBSURBVBI9tTjkTPcesW61s4APiZ2GqWw/JXZqZ3OwvCxib5IrywvAZjPLDK5zPAr83szOItab6X9Q4r0H7p5nZguC+e8i9nbIIvOBX5pZAbF3Qxf9Jie4ISCDWOvj/7n7ioTQSmaOmbULyr/h7lnlrItIMbodV6QcwT/C9d39SHBq7A2gvX/xqlKROkUtDpHynQesCgLEgG8rNKQuU4tDRERC0cVxEREJRcEhIiKhKDhERCQUBYeIiISi4BARkVD+P3a7zWtlzCO7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iteration, total_error, label='Mean squared error for training set')\n",
    "plt.plot(iteration, total_mses, label='Mean squared error for validation set')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('MSE')\n",
    "plt.axis((number_epoc,number_epoc*number_test,0,1))\n",
    "plt.title('')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training stops if any of the following three events occure.\n",
    "    i) The mean square error drops below 0.07.\n",
    "    ii) The mean square error drastically increases that is MSE_new - MSE_last > 0.05.\n",
    "    iii) The mean square error converges and doesn´t change for 5 rounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the final confusion matrix: $$\\text{Confusion} = \\begin{bmatrix} \\text{True One} & \\text{True Zero} \\\\ \\text{False One} & \\text{False Zero} \\end{bmatrix} = \\begin{bmatrix} 39&36\\\\5&2\\end{bmatrix}$$\n",
    "\n",
    "The final accuracy is: $$\\text{Accuracy} = 91.46\\%$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (20 points) Implementation. \n",
    "We will run and check the uploaded Python file. To obtain the points for this subproblem, the Python file has to run (no errors) and the MLP model and the Backpropagation algorithm have to be implemented completely from scratch by you. You are not allowed to use any library which implements MLP models, but you are allowed to use auxiliary libraries, e.g. Numpy, Matplotlib, Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Peer Review paragraph (0 points)\n",
    "Finally, each group member must write a single paragraph outlining their opinion on the work distri- bution within the group. Did every group member contribute equally? Did you split up tasks in a fair manner, or jointly worked through the exercises. Do you think that some members of your group deserve a different grade from others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
