{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 4\n",
    "\n",
    "#### Team members:\n",
    "\n",
    "Arngrímur Einarsson  \n",
    "Guðmundur Orri Pálsson  \n",
    "Nick Geerjens  \n",
    "Stefán Gunnlaugur Jónsson  \n",
    "Troy The Legend  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_excel(\"HW3Avalidate.xlsx\") \n",
    "data_train = pd.read_excel(\"HW3Atrain.xlsx\")\n",
    "\n",
    "X_train = data_train.copy()\n",
    "X_train = X_train.drop('y', axis=1)\n",
    "Y_train = data_train.copy()\n",
    "Y_train = Y_train.drop('X_0', axis=1)\n",
    "Y_train = Y_train.drop('X_1', axis=1)\n",
    "\n",
    "X_test = data_test.copy()\n",
    "X_test = X_test.drop('y', axis=1)\n",
    "Y_test = data_test.copy()\n",
    "Y_test = Y_test.drop('X_0', axis=1)\n",
    "Y_test = Y_test.drop('X_1', axis=1)\n",
    "\n",
    "\n",
    "x_0_min = min(X_train['X_0'])\n",
    "x_0_max = max(X_train['X_0'])\n",
    "\n",
    "x_1_min = min(X_train['X_1'])\n",
    "x_1_max = max(X_train['X_1'])\n",
    "\n",
    "for i in range(len(X_train['X_0'])):\n",
    "    X_train['X_0'][i] = (X_train['X_0'][i]-x_0_min)/(x_0_max-x_0_min) #formula used for Min-Max\n",
    "    X_train['X_1'][i] = (X_train['X_1'][i]-x_1_min)/(x_1_max-x_1_min) #formula used for Min-Max\n",
    "    \n",
    "for i in range(len(X_test['X_0'])):\n",
    "    X_test['X_0'][i] = (X_test['X_0'][i]-x_0_min)/(x_0_max-x_0_min) #formula used for Min-Max\n",
    "    X_test['X_1'][i] = (X_test['X_1'][i]-x_1_min)/(x_1_max-x_1_min) #formula used for Min-Max\n",
    "'''\n",
    "training_data = []\n",
    "for i in range(len(X_train['X_0'])):\n",
    "    training_data.append([round(X_train['X_0'][i], 2),round(X_train['X_1'][i],2)])\n",
    "    \n",
    "testing_data = []\n",
    "for i in range(len(X_test['X_0'])):\n",
    "    testing_data.append([round(X_test['X_0'][i],2),round(X_test['X_1'][i],2)])\n",
    "\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(Y_train['y'])):\n",
    "    y_train.append([Y_train['y'][i]])\n",
    "    \n",
    "y_test = []\n",
    "\n",
    "for i in range(len(Y_test['y'])):\n",
    "    y_test.append([Y_test['y'][i]])\n",
    "'''\n",
    "\n",
    "training_data = np.empty((0,2), int)\n",
    "for i in range(len(X_train['X_0'])):\n",
    "    training_data = np.append(training_data, np.array([[X_train['X_0'][i],X_train['X_1'][i]]]), axis=0)\n",
    "    \n",
    "testing_data = np.empty((0,2), int)\n",
    "for i in range(len(X_test['X_0'])):\n",
    "    testing_data = np.append(testing_data, np.array([[X_test['X_0'][i],X_test['X_1'][i]]]), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "y_train = np.empty((0,1), int)\n",
    "for i in range(len(Y_train['y'])):\n",
    "    y_train = np.append(y_train, np.array([[Y_train['y'][i]]]), axis=0)\n",
    "\n",
    "y_test = np.empty((0,1), int)\n",
    "for i in range(len(Y_test['y'])):\n",
    "    y_test = np.append(y_test, np.array([[Y_test['y'][i]]]), axis=0)\n",
    "\n",
    "np_testing_y = np.array(y_test)\n",
    "np_testing_x = np.array(testing_data)\n",
    "np_training_x = np.array(training_data)\n",
    "np_training_y = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy-iteration: 50.00%\n",
      "Testing accuracy-iteration: 50.00% Learning rate --> 0.009\n",
      "Confusion matrix ---> TrueOne: 0 TrueZero: 41 FalseOne: 0 FalseZero 41\n",
      "MES:  0.5\n",
      "\n",
      "Training accuracy-iteration: 50.00%\n",
      "Testing accuracy-iteration: 50.00% Learning rate --> 0.00873\n",
      "Confusion matrix ---> TrueOne: 0 TrueZero: 41 FalseOne: 0 FalseZero 41\n",
      "MES:  0.5\n",
      "\n",
      "Training accuracy-iteration: 50.00%\n",
      "Testing accuracy-iteration: 50.00% Learning rate --> 0.0084681\n",
      "Confusion matrix ---> TrueOne: 0 TrueZero: 41 FalseOne: 0 FalseZero 41\n",
      "MES:  0.5\n",
      "\n",
      "Training accuracy-iteration: 50.00%\n",
      "Testing accuracy-iteration: 50.00% Learning rate --> 0.008214056999999999\n",
      "Confusion matrix ---> TrueOne: 0 TrueZero: 41 FalseOne: 0 FalseZero 41\n",
      "MES:  0.5\n",
      "\n",
      "Training accuracy-iteration: 50.00%\n",
      "Testing accuracy-iteration: 50.00% Learning rate --> 0.007967635289999999\n",
      "Confusion matrix ---> TrueOne: 0 TrueZero: 41 FalseOne: 0 FalseZero 41\n",
      "MES:  0.5\n",
      "\n",
      "MSE has converged!\n",
      "\n",
      "Average training time for network running 50 iterations with batch size 5 --->0.3968964958190918s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Accuracy-best: 50.00% Learning rate --> 0.009\n",
      "TrueOne: 0 TrueZero: 41 FalseOne: 0 FalseZero 41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Network_layer:\n",
    "    \n",
    "    def __init__(self, number_input, number_neurons, use_standard_activation):\n",
    "        #self.size = size\n",
    "        #self.weights = (np.random.rand(number_input,number_neurons)*2) - 1\n",
    "        #self.weights = np.random.rand(number_input,number_neurons)\n",
    "        self.weights = np.zeros((number_input,number_neurons))\n",
    "        self.bias = np.zeros(number_neurons)\n",
    "        self.last_activation = None\n",
    "        self.use_standard_activation = use_standard_activation\n",
    "        self.error = None\n",
    "        self.delta = None\n",
    "        \n",
    "    def activate(self, x):\n",
    "        r = np.dot(x, self.weights) + self.bias\n",
    "        self.last_activation = self.activation(r)\n",
    "            \n",
    "        return self.last_activation\n",
    "\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def activation(self, x):\n",
    "        #relu\n",
    "        if self.use_standard_activation:\n",
    "            x[x<0] = 0\n",
    "            return x\n",
    "        #tanh\n",
    "        return self.tanh(x)\n",
    "    \n",
    "    def activation_derivative(self, x):\n",
    "        #relu derivative\n",
    "        if self.use_standard_activation:\n",
    "            x[x>0] = 1\n",
    "            x[x<0] = 0\n",
    "            return x\n",
    "        #tanh derivative\n",
    "        return 1.0 - np.tanh(x)**2\n",
    "    \n",
    "\n",
    "class Neaural_net:\n",
    "    layers = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "    \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.activate(X)\n",
    "        return X\n",
    "\n",
    "    def softmax(self,X):\n",
    "        exps = np.exp(X)\n",
    "        return exps / np.sum(exps)\n",
    "    \n",
    "    def cross_entropy(self, X,y):\n",
    "        m = y.shape[0]\n",
    "        p = self.softmax(X)\n",
    "        \n",
    "        likelihood = -np.log(p[range(m), y.argmax(axis=1)])\n",
    "        loss = np.sum(likelihood) / m\n",
    "        return loss\n",
    "        \n",
    "    def logloss(self, true_label, predicted, eps=1e-15):\n",
    "        p = np.clip(predicted, eps, 1 - eps)\n",
    "        if true_label == 1:\n",
    "            return -math.log(p)\n",
    "        else:\n",
    "            return -math.log(1 - p) \n",
    "        \n",
    "    def mae(self, targets, predictions):\n",
    "        differences = predictions - targets\n",
    "        absolute_differences = np.absolute(differences)\n",
    "        mean_absolute_differences = absolute_differences.mean()\n",
    "        return mean_absolute_differences\n",
    "        \n",
    "    def mean_squared_error(self, actual, predicted):\n",
    "        sum_square_error = 0.0\n",
    "        for i in range(len(actual)):\n",
    "            sum_square_error += (actual[i] - predicted[i])**2.0\n",
    "        mean_square_error = sum_square_error / len(actual)\n",
    "\n",
    "        return mean_square_error\n",
    "        \n",
    "    def checkPrediction(self, y, pred):\n",
    "        pred = np.around(pred)\n",
    "        if pred == y:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "               \n",
    "        \n",
    "    def backpropagation(self, X, y, learning_rate):\n",
    "        output = self.feed_forward(X)\n",
    "        average_activation = None\n",
    "        correct_predictions = 0\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            layer = self.layers[i]\n",
    "            all_deltas = []\n",
    "            last_activations = []\n",
    "            for j in range(len(output)):\n",
    "                if layer == self.layers[-1]:\n",
    "                    layer.error =  y[j] - output[j]\n",
    "                    all_deltas.append(layer.error * layer.activation_derivative(output[j]))\n",
    "                    last_activations.append(layer.activation_derivative(output[j]))\n",
    "                    correct_predictions = correct_predictions + self.checkPrediction(y[j], output[j])\n",
    "                else:\n",
    "                    next_layer = self.layers[i + 1]\n",
    "                    layer.error = np.dot(next_layer.weights, next_layer.delta)\n",
    "                    all_deltas.append(layer.error * layer.activation_derivative(layer.last_activation[j]))\n",
    "                    last_activations.append(layer.activation_derivative(layer.last_activation[j]))\n",
    "                    \n",
    "            average_delta = sum(all_deltas)/float(len(output))\n",
    "            average_activation = sum(last_activations)/float(len(output))\n",
    "            layer.delta = average_delta\n",
    "    \n",
    "        # Update the weights\n",
    "        for j in range(len(output)):\n",
    "            for i in range(len(self.layers)):\n",
    "                layer = self.layers[i]\n",
    "                input_to_use = np.atleast_2d(X[j] if i == 0 else self.layers[i - 1].last_activation[j])\n",
    "                layer.weights += layer.delta * input_to_use.T * learning_rate\n",
    "        return correct_predictions\n",
    "            \n",
    "    \n",
    "    \n",
    "    def get_batch(self, inputs, targets, batchsize, shuffle=False):\n",
    "        assert len(inputs) == len(targets)\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(len(inputs))\n",
    "        for start in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "            if shuffle:\n",
    "                excerpt = indices[start:start + batchsize]\n",
    "            else:\n",
    "                excerpt = slice(start, start + batchsize)\n",
    "            yield inputs[excerpt], targets[excerpt] \n",
    "\n",
    "            \n",
    "    def train(self, X, y, learning_rate, max_epochs, batchsize):\n",
    "        mses = []\n",
    "        training_accuracy = []\n",
    "        for i in range(max_epochs):\n",
    "            correct_per_epoch = 0\n",
    "            for x_batch,y_batch in self.get_batch(X,y,batchsize=batchsize,shuffle=False):\n",
    "                correct_predictions_batch = self.backpropagation(x_batch,y_batch, learning_rate)\n",
    "                correct_per_epoch = correct_per_epoch + correct_predictions_batch\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                mse = np.mean(np.square(y - NN.feed_forward(X)))\n",
    "                mses.append(mse)\n",
    "                training_accuracy.append((correct_per_epoch/len(X))*100)\n",
    "        return mses, training_accuracy \n",
    "    \n",
    "    \n",
    "    \n",
    "    def test(self, X, y_true):\n",
    "        correct = 0\n",
    "        TT = 0 \n",
    "        TF = 0\n",
    "        FT = 0\n",
    "        FF = 0\n",
    "        mses = []\n",
    "        forward_passes = []\n",
    "        y_truth_values = []\n",
    "        for i in range(len(X)):\n",
    "            forward_pass = self.feed_forward(X[i])\n",
    "            forward_passes.append(forward_pass)\n",
    "            pred = np.around(forward_pass)\n",
    "            y = y_true[i]\n",
    "            y_truth_values.append(y)\n",
    "            if pred == y:\n",
    "                correct = correct + 1\n",
    "            if pred == 1 and y == 1:\n",
    "                TT = TT + 1\n",
    "            if pred == 1 and y == 0:\n",
    "                FT = FT + 1\n",
    "            if pred == 0 and y == 1:\n",
    "                FF = FF + 1\n",
    "            if pred == 0 and y == 0:\n",
    "                TF = TF + 1\n",
    "            confusion = [TT, TF, FT, FF]\n",
    "        mse = np.mean(np.square(np.array(y_truth_values) - np.array(forward_passes)))\n",
    "        mses.append(mse)\n",
    "        return correct/len(X), confusion, mses\n",
    "\n",
    "def should_break(last_mse, mses, lowest_mse):\n",
    "    stop = False\n",
    "    mse_same = True\n",
    "    for i in range(len(last_mse)):\n",
    "        if round(last_mse[i],4) != round(mses[0],4):\n",
    "            mse_same = False\n",
    "    if mse_same:\n",
    "        print(\"MSE has converged!\")\n",
    "        stop = True\n",
    "    if round(mses[0], 3) < 0.07:\n",
    "        print(\"Error is sufficiently low!\")\n",
    "        stop = True\n",
    "    if round(mses[0],4) - lowest_mse > 0.05:\n",
    "        print(\"MSE increased!\")\n",
    "        stop = True\n",
    "    return stop\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_training(NN, learning_rate = 0.009, batchsize = 5, number_test = 25, number_epoc = 50):\n",
    "    # Train the neural networks\n",
    "    accuracy = []\n",
    "    iteration = []\n",
    "    total_error = []\n",
    "    total_mses = []\n",
    "    total_training_accuracy = []\n",
    "    last_mse = [0,0,0,0,0]\n",
    "    a = 0\n",
    "    total_time = 0\n",
    "    max_accuracy = 0\n",
    "    best_NN = copy.copy(NN)\n",
    "    best_confusion = [0,0,0,0]\n",
    "    best_learning_rate = learning_rate\n",
    "    recall = []\n",
    "    precision = []\n",
    "    lowest_mse = 100\n",
    "    \n",
    "    for i in range(1,number_test+1):\n",
    "        start = time.time()\n",
    "        errors, training_accuracy = NN.train(np_training_x, np_training_y, learning_rate, number_epoc, batchsize)\n",
    "        end = time.time()\n",
    "        total_time = total_time + (end-start)\n",
    "        total_error.append(errors)\n",
    "        total_training_accuracy.append(training_accuracy)\n",
    "        iteration.append(i*number_epoc)\n",
    "        accuracy_one, confusion, mses = NN.test(np_testing_x, np_testing_y)\n",
    "        total_mses.append(mses)\n",
    "        last_mse[a] = round(mses[0],4)\n",
    "        a = a + 1\n",
    "        if a > 4:\n",
    "            a = 0\n",
    "\n",
    "        if(accuracy_one > max_accuracy):\n",
    "            max_accuracy = copy.copy(accuracy_one)\n",
    "            best_NN = copy.deepcopy(NN)\n",
    "            best_confusion = copy.copy(confusion)\n",
    "            best_learning_rate = copy.copy(learning_rate)\n",
    "        if mses[0] < lowest_mse:\n",
    "            lowest_mse = mses[0]\n",
    "        print('Training accuracy-iteration: %.2f%%' % (training_accuracy[-1]))\n",
    "        print('Testing accuracy-iteration: %.2f%%' % (accuracy_one*100), \"Learning rate --> \"+ str(learning_rate))\n",
    "        print('Confusion matrix ---> TrueOne:',confusion[0] ,'TrueZero:',confusion[1], 'FalseOne:',confusion[2] , 'FalseZero',confusion[3] )\n",
    "        print(\"MES: \", mses[0])\n",
    "        print()\n",
    "        #recall_tmp = round(confusion[0]/(confusion[0]+confusion[3]), 2)\n",
    "        #precision_tmp = round(confusion[0]/(confusion[0]+confusion[2]), 2)\n",
    "        #recall.append(recall_tmp)\n",
    "        #print('Recall=', recall_tmp)\n",
    "        #precision.append(precision_tmp)\n",
    "        #print('Precision=', precision_tmp)\n",
    "        accuracy.append(accuracy_one*100)\n",
    "        if should_break(last_mse, mses, lowest_mse):\n",
    "            break;\n",
    "        learning_rate = learning_rate*0.97\n",
    "        \n",
    "    print()\n",
    "    print(\"Average training time for network running \" + str(number_epoc) + \" iterations with batch size \" + str(batchsize) + \" --->\" + str(total_time/number_test)+ \"s\")\n",
    "    plt.plot(iteration,accuracy, label='Validation accuracy')\n",
    "    #plt.plot(iteration, total_error, label='Mean squared error for training set')\n",
    "    #plt.plot(iteration, total_mses, label='Mean squared error for validation set')\n",
    "    plt.plot(iteration, total_training_accuracy, label='Training accuracy')\n",
    "    #plt.plot(iteration, recall, label='Recall')\n",
    "    #plt.plot(iteration, precision, label='Precision')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('Accuracy & MSE(*100)')\n",
    "    plt.axis((number_epoc,number_epoc*number_test,0,100))\n",
    "    plt.title('')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    accuracy_one, confusion, mses = best_NN.test(np_testing_x, np_testing_y)\n",
    "    print(\"------------------------\")\n",
    "    print('Accuracy-best: %.2f%%' % (accuracy_one*100), \"Learning rate --> \"+ str(best_learning_rate))\n",
    "    print('TrueOne:',confusion[0] ,'TrueZero:',confusion[1], 'FalseOne:',confusion[2] , 'FalseZero',confusion[3] )\n",
    "    print()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def init_net(hidden_layers):\n",
    "    NN = Neaural_net()\n",
    "    NN.add_layer(Network_layer(2, 10, False))\n",
    "    for i in range(hidden_layers - 1):\n",
    "        NN.add_layer(Network_layer(10, 10, False))\n",
    "    NN.add_layer(Network_layer(10,1, False))\n",
    "    return NN\n",
    "\n",
    "\n",
    "NN = init_net(2)\n",
    "run_training(NN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (10 points) Parameter initialization. \n",
    "\n",
    "Choose the best performing model from HW3A in termsof classification accuracy. For this model, initialize all its parameters (connection weights and biases) to zero and retrain it using all the other settings from HW3A. Report the performance (e.g.loss function over training epochs, classi\f",
    "cation accuracy and confusion matrix on the validation set after training) of this new trained model. Do you observe any interesting behavior for this\n",
    "new trained model? Discuss the performance of this new trained model in comparison with the\n",
    "performance of the best model from HW3A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy is stuck at $50\\%$ when the weights and bias are initialized to zero. In each iteration of the backpropigation, we update the weights by multiplying the existing weight by a delta determined by backpropagation. If the initial weights value are zeros, multiplying it by any value for delta won't change the weight which means each iteration has no effect on the weights you're trying to optimize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (10 points) Learning rate vs parameter initialization. \n",
    "\n",
    "Retrain several times for the same fixed amount of epochs (e.g. 100 - this value is your choice) the best model from HW3A using exactly the same settings as in HW3A, with the exception of the learning rate and the initialization of the connection weights and biases which have to be different for each retraining. Start with a very small learning rate (e.g. 0:0001) and after that gradually increase it (e.g. next values can be\n",
    ":001, 0:01, ...). Initialize the connection weights and biases by sampling from a normal distribution\n",
    "$N(0, \\sigma^2)$ has to take the following values $\\{0; 0.1; 0.2; 0.3; 0.4; 0.5; 0.6; 0.7; 0.8; 0.9; 1\\}$. Make a heatmap where the x-axis represents $\\sigma^2$, the y-axis represents the learning rate, while the colors\n",
    "represent the accuracy obtained on the validation set after each training. Each element in the\n",
    "heatmap matrix represents practically the accuracy obtained with a specific learning rate and a\n",
    "specific initialization. Discuss the heatmap results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started with the learning rate as 0.009 and after each test the learning rate was reduced by 1%. We tried various batch sizes, what worked best was relatively small batch sizes so we ended using \n",
    "$$batchsize=5$$\n",
    "We initialized our weights as a random number from 0 to 1 and our biases as 0. We read that it is best to initialize biases as zero, it also didn´t give good results when we tried random to initilaze the biases. We knew that using random initialization for the weights is better than using zeroes. We tried some other initilizations such as from 0 to 0.5 or -0.5 to 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (10 points) Training. \n",
    "Make plots with the loss function computed over the training set and over the validation set. Stop the training when the error is small enough. Justify your stopping criterium. Report the final accuracy obtained and the confusion matrix on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iteration, total_error, label='Mean squared error for training set')\n",
    "plt.plot(iteration, total_mses, label='Mean squared error for validation set')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('MSE')\n",
    "plt.axis((number_epoc,number_epoc*number_test,0,1))\n",
    "plt.title('')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training stops if any of the following three events occure.\n",
    "    i) The mean square error drops below 0.07.\n",
    "    ii) The mean square error drastically increases that is MSE_new - MSE_last > 0.05.\n",
    "    iii) The mean square error converges and doesn´t change for 5 rounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the final confusion matrix: $$\\text{Confusion} = \\begin{bmatrix} \\text{True One} & \\text{True Zero} \\\\ \\text{False One} & \\text{False Zero} \\end{bmatrix} = \\begin{bmatrix} 39&36\\\\5&2\\end{bmatrix}$$\n",
    "\n",
    "The final accuracy is: $$\\text{Accuracy} = 91.46\\%$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (20 points) Implementation. \n",
    "We will run and check the uploaded Python file. To obtain the points for this subproblem, the Python file has to run (no errors) and the MLP model and the Backpropagation algorithm have to be implemented completely from scratch by you. You are not allowed to use any library which implements MLP models, but you are allowed to use auxiliary libraries, e.g. Numpy, Matplotlib, Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Peer Review paragraph (0 points)\n",
    "Finally, each group member must write a single paragraph outlining their opinion on the work distri- bution within the group. Did every group member contribute equally? Did you split up tasks in a fair manner, or jointly worked through the exercises. Do you think that some members of your group deserve a different grade from others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
